<!DOCTYPE html>
<html lang="en">
  <head>
    <title>  Reference</title>
    <link rel="stylesheet" type="text/css" href="css/jazzy.css" />
    <link rel="stylesheet" type="text/css" href="css/highlight.css" />
    <meta charset='utf-8'>
    <script src="js/jquery.min.js" defer></script>
    <script src="js/jazzy.js" defer></script>
    
  </head>
  <body>
    <a title="  Reference"></a>
    <header>
      <div class="content-wrapper">
        <p><a href="index.html"> Docs</a></p>
        <p class="header-right"><a href="https://github.com/watson-developer-cloud/ios-sdk"><img src="img/gh.png"/>View on GitHub</a></p>
      </div>
    </header>
    <div class="content-wrapper">
      <p id="breadcrumbs">
        <a href="index.html"> Reference</a>
        <img id="carat" src="img/carat.png" />
          Reference
      </p>
    </div>
    <div class="content-wrapper">
      <nav class="sidebar">
        <ul class="nav-groups">
          <li class="nav-group-name">
            <a href="Classes.html">Classes</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Classes/VisualRecognition.html">VisualRecognition</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Enums.html">Enumerations</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Enums/JSON.html">JSON</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/RestError.html">RestError</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Structs.html">Structures</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Structs/Class.html">Class</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/ClassResult.html">ClassResult</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/ClassifiedImage.html">ClassifiedImage</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/ClassifiedImages.html">ClassifiedImages</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Classifier.html">Classifier</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Classifier/Status.html">– Status</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/ClassifierResult.html">ClassifierResult</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Classifiers.html">Classifiers</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/DetectedFaces.html">DetectedFaces</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/ErrorInfo.html">ErrorInfo</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Face.html">Face</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/FaceAge.html">FaceAge</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/FaceGender.html">FaceGender</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/FaceIdentity.html">FaceIdentity</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/FaceLocation.html">FaceLocation</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/ImageWithFaces.html">ImageWithFaces</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/PositiveExample.html">PositiveExample</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/WarningInfo.html">WarningInfo</a>
              </li>
            </ul>
          </li>
        </ul>
      </nav>
      <article class="main-content">
        <section>
          <section class="section">
            
            <h1 id='watson-developer-cloud-swift-sdk' class='heading'>Watson Developer Cloud Swift SDK</h1>

<p><a href="https://travis-ci.org/watson-developer-cloud/swift-sdk"><img src="https://travis-ci.org/watson-developer-cloud/swift-sdk.svg?branch=master" alt="Build Status"></a>
<img src="https://img.shields.io/badge/platform-iOS,%20Linux-blue.svg?style=flat" alt="">
<a href="https://github.com/Carthage/Carthage"><img src="https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat" alt="Carthage Compatible"></a>
<a href="http://watson-developer-cloud.github.io/swift-sdk"><img src="https://img.shields.io/badge/Documentation-API-blue.svg" alt="Documentation"></a>
<a href="https://cla-assistant.io/watson-developer-cloud/swift-sdk"><img src="https://cla-assistant.io/readme/badge/watson-developer-cloud/swift-sdk" alt="CLA assistant"></a></p>
<h2 id='overview' class='heading'>Overview</h2>

<p>The Watson Developer Cloud Swift SDK makes it easy for mobile developers to build Watson-powered applications. With the Swift SDK you can leverage the power of Watson&rsquo;s advanced artificial intelligence, machine learning, and deep learning techniques to understand unstructured data and engage with mobile users in new ways.</p>

<p>There are many resources to help you build your first cognitive application with the Swift SDK:</p>

<ul>
<li>Read the <a href="README.md">Readme</a></li>
<li>Follow the <a href="docs/quickstart.md">QuickStart Guide</a></li>
<li>Review a <a href="#sample-applications">Sample Application</a></li>
<li>Browse the <a href="http://watson-developer-cloud.github.io/swift-sdk/">Documentation</a></li>
</ul>
<h2 id='contents' class='heading'>Contents</h2>
<h3 id='general' class='heading'>General</h3>

<ul>
<li><a href="#before-you-begin">Before you begin</a></li>
<li><a href="#requirements">Requirements</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#service-instances">Service Instances</a></li>
<li><a href="#custom-service-urls">Custom Service URLs</a></li>
<li><a href="#custom-headers">Custom Headers</a></li>
<li><a href="#sample-applications">Sample Applications</a></li>
<li><a href="#synchronous-execution">Synchronous Execution</a></li>
<li><a href="#objective-c-compatibility">Objective-C Compatibility</a></li>
<li><a href="#linux-compatibility">Linux Compatibility</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#license">License</a></li>
</ul>
<h3 id='services' class='heading'>Services</h3>

<ul>
<li><a href="#assistant">Assistant</a></li>
<li><a href="#discovery">Discovery</a></li>
<li><a href="#language-translator-v2">Language Translator V2</a></li>
<li><a href="#language-translator-v3">Language Translator V3</a></li>
<li><a href="#natural-language-classifier">Natural Language Classifier</a></li>
<li><a href="#natural-language-understanding">Natural Language Understanding</a></li>
<li><a href="#personality-insights">Personality Insights</a></li>
<li><a href="#speech-to-text">Speech to Text</a></li>
<li><a href="#text-to-speech">Text to Speech</a></li>
<li><a href="#tone-analyzer">Tone Analyzer</a></li>
<li><a href="#visual-recognition">Visual Recognition</a></li>
</ul>
<h2 id='before-you-begin' class='heading'>Before you begin</h2>

<ul>
<li>You need an <a href="http://console.bluemix.net/registration?target=/developer/watson&cm_sp=WatsonPlatform-WatsonServices-_-OnPageNavLink-IBMWatson_SDKs-_-Swift">IBM Cloud</a> account.</li>
</ul>
<h2 id='requirements' class='heading'>Requirements</h2>

<ul>
<li>iOS 8.0+</li>
<li>Xcode 9.0+</li>
<li>Swift 3.2+ or Swift 4.0+</li>
</ul>
<h2 id='installation' class='heading'>Installation</h2>
<h3 id='dependency-management' class='heading'>Dependency Management</h3>

<p>We recommend using <a href="https://github.com/Carthage/Carthage">Carthage</a> to manage dependencies and build the Swift SDK for your application.</p>

<p>You can install Carthage with <a href="http://brew.sh/">Homebrew</a>:</p>
<pre class="highlight shell"><code><span class="nv">$ </span>brew update
<span class="nv">$ </span>brew <span class="nb">install </span>carthage
</code></pre>

<p>Then, navigate to the root directory of your project (where your .xcodeproj file is located) and create an empty <code>Cartfile</code> there:</p>
<pre class="highlight shell"><code><span class="nv">$ </span><span class="nb">touch </span>Cartfile
</code></pre>

<p>To use the Watson Developer Cloud Swift SDK in your application, specify it in your <code>Cartfile</code>:</p>
<pre class="highlight plaintext"><code>github "watson-developer-cloud/swift-sdk"
</code></pre>

<p>In a production app, you may also want to specify a <a href="https://github.com/Carthage/Carthage/blob/master/Documentation/Artifacts.md#version-requirement">version requirement</a>.</p>

<p>Then run the following command to build the dependencies and frameworks:</p>
<pre class="highlight shell"><code><span class="nv">$ </span>carthage update <span class="nt">--platform</span> iOS
</code></pre>

<p>Finally, drag-and-drop the built frameworks into your Xcode project and import them as desired. If you are using Speech to Text, be sure to include both <code>SpeechToTextV1.framework</code> and <code>Starscream.framework</code> in your application.</p>
<h3 id='swift-package-manager' class='heading'>Swift Package Manager</h3>

<p>Add the following to your <code>Package.swift</code> file to identify the Swift SDK as a dependency. The package manager will clone the Swift SDK when you build your project with <code>swift build</code>.</p>
<pre class="highlight swift"><code><span class="nv">dependencies</span><span class="p">:</span> <span class="p">[</span>
    <span class="o">.</span><span class="nf">package</span><span class="p">(</span><span class="nv">url</span><span class="p">:</span> <span class="s">"https://github.com/watson-developer-cloud/swift-sdk"</span><span class="p">,</span> <span class="nv">from</span><span class="p">:</span> <span class="s">"0.29.0"</span><span class="p">)</span>
<span class="p">]</span>
</code></pre>
<h2 id='service-instances' class='heading'>Service Instances</h2>

<p><a href="https://www.ibm.com/watson/developer/">IBM Watson</a> offers a variety of services for developing cognitive applications. The complete list of Watson services is available from the <a href="https://www.ibm.com/watson/products-services/">products and services</a> page. Services are instantiated using the <a href="https://www.ibm.com/cloud/">IBM Cloud</a> platform.</p>

<p>Follow these steps to create a service instance and obtain its credentials:</p>

<ol>
<li>Log in to IBM Cloud at <a href="https://bluemix.net">https://bluemix.net</a>.</li>
<li>Create a service instance:

<ol>
<li>From the Dashboard, select <q>Use Services or APIs</q>.</li>
<li>Select the service you want to use.</li>
<li>Click <q>Create</q>.</li>
</ol></li>
<li>Copy your service credentials:

<ol>
<li>Click <q>Service Credentials</q> on the left side of the page.</li>
<li>Copy the service&rsquo;s <code>username</code> and <code>password</code> (or <code>api_key</code> for Visual Recognition).</li>
</ol></li>
</ol>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">textToSpeech</span> <span class="o">=</span> <span class="kt">TextToSpeech</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="s">"your-username-here"</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="s">"your-password-here"</span><span class="p">)</span>
</code></pre>

<p>Note that service credentials are different from your IBM Cloud username and password.</p>

<p>See <a href="https://console.bluemix.net/docs/services/watson/index.html">Getting started with Watson and IBM Cloud</a> for details.</p>
<h2 id='authentication' class='heading'>Authentication</h2>

<p>There are three ways to authenticate with IBM Cloud through the SDK: using a <code>username</code> and <code>password</code>, using an <code>api_key</code>, and with IAM.</p>

<p>See above for the steps to obtain the credentials for your service.</p>

<p>In your code, you pass these values in the service constructor when instantiating your service. Here are some examples:</p>
<h3 id='username-and-password' class='heading'>Username and Password</h3>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">discovery</span> <span class="o">=</span> <span class="kt">Discovery</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="s">"your-username-here"</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="s">"your-password-here"</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="s">"your-version-here"</span><span class="p">)</span>
</code></pre>
<h3 id='api-key' class='heading'>API Key</h3>

<p><em>Note: This type of authentication only works with Visual Recognition, and for instances created before May 23, 2018. Newer instances of Visual Recognition use IAM.</em></p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">visualRecognition</span> <span class="o">=</span> <span class="kt">VisualRecognition</span><span class="p">(</span><span class="nv">apiKey</span><span class="p">:</span> <span class="s">"your-apiKey-here"</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="s">"your-version-here"</span><span class="p">)</span>
</code></pre>
<h3 id='using-iam' class='heading'>Using IAM</h3>

<p>When authenticating with IAM, you have the option of supplying:</p>

<ul>
<li>the IAM API key and, optionally, the IAM service URL. The IAM service URL defaults to &lsquo;<a href="https://iam.bluemix.net/identity/token">https://iam.bluemix.net/identity/token</a>&rsquo;.</li>
<li>an access token for the service.</li>
</ul>

<p>If you supply an IAM API key, the SDK will request and refresh access tokens on your behalf.
If you supply only the IAM access token, you are responsible for refreshing the access token as needed.</p>
<h4 id='supplying-the-iam-api-key' class='heading'>Supplying the IAM API key</h4>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">discovery</span> <span class="o">=</span> <span class="kt">Discovery</span><span class="p">(</span><span class="nv">version</span><span class="p">:</span> <span class="s">"your-version-here"</span><span class="p">,</span> <span class="nv">apiKey</span><span class="p">:</span> <span class="s">"your-apikey-here"</span><span class="p">)</span>
</code></pre>
<h4 id='supplying-the-accesstoken' class='heading'>Supplying the accessToken</h4>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">discovery</span> <span class="o">=</span> <span class="kt">Discovery</span><span class="p">(</span><span class="nv">version</span><span class="p">:</span> <span class="s">"your-version-here"</span><span class="p">,</span> <span class="nv">accessToken</span><span class="p">:</span> <span class="s">"your-accessToken-here"</span><span class="p">)</span>
</code></pre>
<h4 id='updating-the-accesstoken' class='heading'>Updating the accessToken</h4>
<pre class="highlight swift"><code><span class="n">discovery</span><span class="o">.</span><span class="nf">accessToken</span><span class="p">(</span><span class="s">"new-accessToken-here"</span><span class="p">)</span>
</code></pre>
<h2 id='custom-service-urls' class='heading'>Custom Service URLs</h2>

<p>You can set a custom service URL by modifying the <code>serviceURL</code> property. A custom service URL may be required when running an  instance in a particular region or connecting through a proxy.</p>

<p>For example, here is how to connect to a Tone Analyzer instance that is hosted in Germany:</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">toneAnalyzer</span> <span class="o">=</span> <span class="kt">ToneAnalyzer</span><span class="p">(</span>
    <span class="nv">username</span><span class="p">:</span> <span class="s">"your-username-here"</span><span class="p">,</span>
    <span class="nv">password</span><span class="p">:</span> <span class="s">"your-password-here"</span><span class="p">,</span>
    <span class="nv">version</span><span class="p">:</span> <span class="s">"yyyy-mm-dd"</span>
<span class="p">)</span>
<span class="n">toneAnalyzer</span><span class="o">.</span><span class="n">serviceURL</span> <span class="o">=</span> <span class="s">"https://gateway-fra.watsonplatform.net/tone-analyzer/api"</span>
</code></pre>
<h2 id='custom-headers' class='heading'>Custom Headers</h2>

<p>There are different headers that can be sent to the Watson services. For example, Watson services log requests and their results for the purpose of improving the services, but you can include the <code>X-Watson-Learning-Opt-Out</code> header to opt out of this.</p>

<p>We have exposed a <code>defaultHeaders</code> public property in each class to allow users to easily customize their headers:</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">naturalLanguageClassifier</span> <span class="o">=</span> <span class="kt">NaturalLanguageClassifier</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">)</span>
<span class="n">naturalLanguageClassifier</span><span class="o">.</span><span class="n">defaultHeaders</span> <span class="o">=</span> <span class="p">[</span><span class="s">"X-Watson-Learning-Opt-Out"</span><span class="p">:</span> <span class="s">"true"</span><span class="p">]</span>
</code></pre>

<p>Each service method also accepts an optional <code>headers</code> parameter which is a dictionary of request headers to be sent with the request.</p>
<h2 id='sample-applications' class='heading'>Sample Applications</h2>

<ul>
<li><a href="https://github.com/watson-developer-cloud/simple-chat-swift">Simple Chat (Swift)</a></li>
<li><a href="https://github.com/watson-developer-cloud/simple-chat-objective-c">Simple Chat (Objective-C)</a></li>
<li><a href="https://github.com/watson-developer-cloud/visual-recognition-coreml">Visual Recognition with Core ML</a></li>
<li><a href="https://github.com/watson-developer-cloud/visual-recognition-with-discovery-coreml">Visual Recognition and Discovery with Core ML</a></li>
<li><a href="https://github.com/watson-developer-cloud/speech-to-text-swift">Speech to Text</a></li>
<li><a href="https://github.com/watson-developer-cloud/text-to-speech-swift">Text to Speech</a></li>
<li><a href="https://github.com/IBM-MIL/CognitiveConcierge">Cognitive Concierge</a></li>
</ul>
<h2 id='synchronous-execution' class='heading'>Synchronous Execution</h2>

<p>By default, the SDK executes all networking operations asynchonously. If your application requires synchronous execution, you can use a <code>DispatchGroup</code>. For example:</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">dispatchGroup</span> <span class="o">=</span> <span class="kt">DispatchGroup</span><span class="p">()</span>
<span class="n">dispatchGroup</span><span class="o">.</span><span class="nf">enter</span><span class="p">()</span>
<span class="n">assistant</span><span class="o">.</span><span class="nf">message</span><span class="p">(</span><span class="nv">workspaceID</span><span class="p">:</span> <span class="n">workspaceID</span><span class="p">)</span> <span class="p">{</span> <span class="n">response</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
    <span class="n">dispatchGroup</span><span class="o">.</span><span class="nf">leave</span><span class="p">()</span>
<span class="p">}</span>
<span class="n">dispatchGroup</span><span class="o">.</span><span class="nf">wait</span><span class="p">(</span><span class="nv">timeout</span><span class="p">:</span> <span class="o">.</span><span class="n">distantFuture</span><span class="p">)</span>
</code></pre>
<h2 id='objective-c-compatibility' class='heading'>Objective-C Compatibility</h2>

<p>Please see <a href="docs/objective-c.md">this tutorial</a> for more information about consuming the Watson Developer Cloud Swift SDK in an Objective-C application.</p>
<h2 id='linux-compatibility' class='heading'>Linux Compatibility</h2>

<p>To use the Watson SDK in your Linux project, please follow the <a href="#swift-package-manager">Swift Package Manager instructions.</a>. Note that Speech to Text and Text to Speech are not supported because they rely on frameworks that are unavailable on Linux.</p>
<h2 id='contributing' class='heading'>Contributing</h2>

<p>We would love any and all help! If you would like to contribute, please read our <a href="https://github.com/watson-developer-cloud/swift-sdk/blob/master/.github/CONTRIBUTING.md">CONTRIBUTING</a> documentation with information on getting started.</p>
<h2 id='license' class='heading'>License</h2>

<p>This library is licensed under Apache 2.0. Full license text is
available in <a href="https://github.com/watson-developer-cloud/swift-sdk/blob/master/LICENSE">LICENSE</a>.</p>

<p>This SDK is intended for use with an Apple iOS product and intended to be used in conjunction with officially licensed Apple development tools.</p>
<h2 id='assistant' class='heading'>Assistant</h2>

<p>With the IBM Watson Assistant service you can create cognitive agents&ndash;virtual agents that combine machine learning, natural language understanding, and integrated dialog scripting tools to provide outstanding customer engagements.</p>

<p>The following example shows how to start a conversation with the Assistant service:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">AssistantV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">version</span> <span class="o">=</span> <span class="s">"YYYY-MM-DD"</span> <span class="c1">// use today's date for the most recent version</span>
<span class="k">let</span> <span class="nv">assistant</span> <span class="o">=</span> <span class="kt">Assistant</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">workspaceID</span> <span class="o">=</span> <span class="s">"your-workspace-id-here"</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="k">var</span> <span class="nv">context</span><span class="p">:</span> <span class="kt">Context</span><span class="p">?</span> <span class="c1">// save context to continue conversation</span>
<span class="n">assistant</span><span class="o">.</span><span class="nf">message</span><span class="p">(</span><span class="nv">workspaceID</span><span class="p">:</span> <span class="n">workspaceID</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">response</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">context</span>
<span class="p">}</span>
</code></pre>

<p>The following example shows how to continue an existing conversation with the Assistant service:</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">input</span> <span class="o">=</span> <span class="kt">InputData</span><span class="p">(</span><span class="nv">text</span><span class="p">:</span> <span class="s">"Turn on the radio."</span><span class="p">)</span>
<span class="k">let</span> <span class="nv">request</span> <span class="o">=</span> <span class="kt">MessageRequest</span><span class="p">(</span><span class="nv">input</span><span class="p">:</span> <span class="n">input</span><span class="p">,</span> <span class="nv">context</span><span class="p">:</span> <span class="n">context</span><span class="p">)</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">assistant</span><span class="o">.</span><span class="nf">message</span><span class="p">(</span><span class="nv">workspaceID</span><span class="p">:</span> <span class="n">workspaceID</span><span class="p">,</span> <span class="nv">request</span><span class="p">:</span> <span class="n">request</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">response</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">context</span>
<span class="p">}</span>
</code></pre>
<h4 id='context-variables' class='heading'>Context Variables</h4>

<p>The Assistant service allows users to define custom context variables in their application&rsquo;s payload. For example, a workspace that guides users through a pizza order might include a context variable for pizza size: <code>&quot;pizza_size&quot;: &quot;large&quot;</code>.</p>

<p>Context variables are get/set using the <code>var additionalProperties: [String: JSON]</code> property of a <code>Context</code> model. The following example shows how to get and set a user-defined <code>pizza_size</code> variable:</p>
<pre class="highlight swift"><code><span class="c1">// get the `pizza_size` context variable</span>
<span class="n">assistant</span><span class="o">.</span><span class="nf">message</span><span class="p">(</span><span class="nv">workspaceID</span><span class="p">:</span> <span class="n">workspaceID</span><span class="p">,</span> <span class="nv">request</span><span class="p">:</span> <span class="n">request</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">response</span> <span class="k">in</span>
    <span class="k">if</span> <span class="k">case</span> <span class="kd">let</span> <span class="o">.</span><span class="nf">string</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">additionalProperties</span><span class="p">[</span><span class="s">"pizza_size"</span><span class="p">]</span><span class="o">!</span> <span class="p">{</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// set the `pizza_size` context variable</span>
<span class="n">assistant</span><span class="o">.</span><span class="nf">message</span><span class="p">(</span><span class="nv">workspaceID</span><span class="p">:</span> <span class="n">workspaceID</span><span class="p">,</span> <span class="nv">request</span><span class="p">:</span> <span class="n">request</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">response</span> <span class="k">in</span>
    <span class="k">var</span> <span class="nv">context</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">context</span> <span class="c1">// `var` makes the context mutable</span>
    <span class="n">context</span><span class="p">?</span><span class="o">.</span><span class="n">additionalProperties</span><span class="p">[</span><span class="s">"pizza_size"</span><span class="p">]</span> <span class="o">=</span> <span class="o">.</span><span class="nf">string</span><span class="p">(</span><span class="s">"large"</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>For reference, the <code><a href="Enums/JSON.html">JSON</a></code> type is defined as:</p>
<pre class="highlight swift"><code><span class="c1">/// A JSON value (one of string, number, object, array, true, false, or null).</span>
<span class="kd">public</span> <span class="kd">enum</span> <span class="kt">JSON</span><span class="p">:</span> <span class="kt">Equatable</span><span class="p">,</span> <span class="kt">Codable</span> <span class="p">{</span>
    <span class="k">case</span> <span class="n">null</span>
    <span class="k">case</span> <span class="nf">boolean</span><span class="p">(</span><span class="kt">Bool</span><span class="p">)</span>
    <span class="k">case</span> <span class="nf">string</span><span class="p">(</span><span class="kt">String</span><span class="p">)</span>
    <span class="k">case</span> <span class="nf">int</span><span class="p">(</span><span class="kt">Int</span><span class="p">)</span>
    <span class="k">case</span> <span class="nf">double</span><span class="p">(</span><span class="kt">Double</span><span class="p">)</span>
    <span class="k">case</span> <span class="nf">array</span><span class="p">([</span><span class="kt">JSON</span><span class="p">])</span>
    <span class="k">case</span> <span class="nf">object</span><span class="p">([</span><span class="kt">String</span><span class="p">:</span> <span class="kt">JSON</span><span class="p">])</span>
<span class="p">}</span>
</code></pre>

<p>The following links provide more information about the IBM Watson Assistant service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/conversation/">IBM Watson Assistant - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/conversation/index.html">IBM Watson Assistant - Documentation</a></li>
</ul>
<h2 id='discovery' class='heading'>Discovery</h2>

<p>IBM Watson Discovery makes it possible to rapidly build cognitive, cloud-based exploration applications that unlock actionable insights hidden in unstructured data — including your own proprietary data, as well as public and third-party data. With Discovery, it only takes a few steps to prepare your unstructured data, create a query that will pinpoint the information you need, and then integrate those insights into your new application or existing solution.</p>
<h3 id='discovery-news' class='heading'>Discovery News</h3>

<p>IBM Watson Discovery News is included with Discovery. Watson Discovery News is an indexed dataset with news articles from the past 60 days — approximately 300,000 English articles daily. The dataset is pre-enriched with the following cognitive insights: Keyword Extraction, Entity Extraction, Semantic Role Extraction, Sentiment Analysis, Relation Extraction, and Category Classification.</p>

<p>The following example shows how to query the Watson Discovery News dataset:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">DiscoveryV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">version</span> <span class="o">=</span> <span class="s">"YYYY-MM-DD"</span> <span class="c1">// use today's date for the most recent version</span>
<span class="k">let</span> <span class="nv">discovery</span> <span class="o">=</span> <span class="kt">Discovery</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">failure</span><span class="p">)</span> <span class="p">}</span>
<span class="n">discovery</span><span class="o">.</span><span class="nf">query</span><span class="p">(</span>
    <span class="nv">environmentID</span><span class="p">:</span> <span class="s">"system"</span><span class="p">,</span>
    <span class="nv">collectionID</span><span class="p">:</span> <span class="s">"news-en"</span><span class="p">,</span>
    <span class="nv">query</span><span class="p">:</span> <span class="s">"enriched_text.concepts.text:</span><span class="se">\"</span><span class="s">Cloud computing</span><span class="se">\"</span><span class="s">"</span><span class="p">,</span>
    <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">queryResponse</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">queryResponse</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>
<h3 id='private-data-collections' class='heading'>Private Data Collections</h3>

<p>The Swift SDK supports environment management, collection management, and document uploading. But you may find it easier to create private data collections using the <a href="https://console.bluemix.net/docs/services/discovery/getting-started-tool.html#getting-started-with-the-tooling">Discovery Tooling</a> instead.</p>

<p>Once your content has been uploaded and enriched by the Discovery service, you can search the collection with queries. The following example demonstrates a complex query with a filter, query, and aggregation:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">DiscoveryV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">version</span> <span class="o">=</span> <span class="s">"YYYY-MM-DD"</span> <span class="c1">// use today's date for the most recent version</span>
<span class="k">let</span> <span class="nv">discovery</span> <span class="o">=</span> <span class="kt">Discovery</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">failure</span><span class="p">)</span> <span class="p">}</span>
<span class="n">discovery</span><span class="o">.</span><span class="nf">query</span><span class="p">(</span>
    <span class="nv">environmentID</span><span class="p">:</span> <span class="s">"your-environment-id"</span><span class="p">,</span>
    <span class="nv">collectionID</span><span class="p">:</span> <span class="s">"your-collection-id"</span><span class="p">,</span>
    <span class="nv">filter</span><span class="p">:</span> <span class="s">"enriched_text.concepts.text:</span><span class="se">\"</span><span class="s">Technology</span><span class="se">\"</span><span class="s">"</span><span class="p">,</span>
    <span class="nv">query</span><span class="p">:</span> <span class="s">"enriched_text.concepts.text:</span><span class="se">\"</span><span class="s">Cloud computing</span><span class="se">\"</span><span class="s">"</span><span class="p">,</span>
    <span class="nv">aggregation</span><span class="p">:</span> <span class="s">"term(enriched_text.concepts.text,count:10)"</span><span class="p">,</span>
    <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">queryResponse</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">queryResponse</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>You can also upload new documents into your private collection:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">DiscoveryV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">version</span> <span class="o">=</span> <span class="s">"YYYY-MM-DD"</span> <span class="c1">// use today's date for the most recent version</span>
<span class="k">let</span> <span class="nv">discovery</span> <span class="o">=</span> <span class="kt">Discovery</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">failure</span><span class="p">)</span> <span class="p">}</span>
<span class="k">let</span> <span class="nv">file</span> <span class="o">=</span> <span class="kt">Bundle</span><span class="o">.</span><span class="n">main</span><span class="o">.</span><span class="nf">url</span><span class="p">(</span><span class="nv">forResource</span><span class="p">:</span> <span class="s">"KennedySpeech"</span><span class="p">,</span> <span class="nv">withExtension</span><span class="p">:</span> <span class="s">"html"</span><span class="p">)</span><span class="o">!</span>
<span class="n">discovery</span><span class="o">.</span><span class="nf">addDocument</span><span class="p">(</span>
    <span class="nv">environmentID</span><span class="p">:</span> <span class="s">"your-environment-id"</span><span class="p">,</span>
    <span class="nv">collectionID</span><span class="p">:</span> <span class="s">"your-collection-id"</span><span class="p">,</span>
    <span class="nv">file</span><span class="p">:</span> <span class="n">file</span><span class="p">,</span>
    <span class="nv">fileContentType</span><span class="p">:</span> <span class="s">"text/html"</span><span class="p">,</span>
    <span class="nv">failure</span><span class="p">:</span> <span class="n">failWithError</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">response</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>The following links provide more information about the IBM Discovery service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/discovery/">IBM Discovery - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/discovery/index.html">IBM Discovery - Documentation</a></li>
<li><a href="https://discovery-news-demo.ng.bluemix.net/">IBM Discovery - Demo</a></li>
</ul>
<h2 id='language-translator-v2' class='heading'>Language Translator V2</h2>
<h3 id='deprecation-notice' class='heading'>Deprecation notice</h3>

<p>Language Translator v3 is now available. The v2 Language Translator API will no longer be available after July 31, 2018.
To take advantage of the latest service enhancements, migrate to the v3 API.
View the <a href="https://console.bluemix.net/docs/services/language-translator/migrating.html">Migrating to Language Translator v3</a> page for more information.</p>
<h2 id='language-translator-v3' class='heading'>Language Translator V3</h2>

<p>The IBM Watson Language Translator service lets you select a domain, customize it, then identify or select the language of text, and then translate the text from one supported language to another.</p>

<p>The following example demonstrates how to use the Language Translator service:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">LanguageTranslatorV3</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">version</span> <span class="o">=</span> <span class="s">"yyyy-mm-dd"</span> <span class="c1">// use today's date for the most recent version</span>
<span class="k">let</span> <span class="nv">languageTranslator</span> <span class="o">=</span> <span class="kt">LanguageTranslator</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="k">let</span> <span class="nv">request</span> <span class="o">=</span> <span class="kt">TranslateRequest</span><span class="p">(</span><span class="nv">text</span><span class="p">:</span> <span class="p">[</span><span class="s">"Hello"</span><span class="p">],</span> <span class="nv">source</span><span class="p">:</span> <span class="s">"en"</span><span class="p">,</span> <span class="nv">target</span><span class="p">:</span> <span class="s">"es"</span><span class="p">)</span>
<span class="n">languageTranslator</span><span class="o">.</span><span class="nf">translate</span><span class="p">(</span><span class="nv">request</span><span class="p">:</span> <span class="n">request</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">translation</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">translation</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>The following links provide more information about the IBM Watson Language Translator service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/language-translator/">IBM Watson Language Translator - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/language-translator/index.html">IBM Watson Language Translator - Documentation</a></li>
<li><a href="https://language-translator-demo.ng.bluemix.net/">IBM Watson Language Translator - Demo</a></li>
</ul>
<h2 id='natural-language-classifier' class='heading'>Natural Language Classifier</h2>

<p>The IBM Watson Natural Language Classifier service enables developers without a background in machine learning or statistical algorithms to create natural language interfaces for their applications. The service interprets the intent behind text and returns a corresponding classification with associated confidence levels. The return value can then be used to trigger a corresponding action, such as redirecting the request or answering a question.</p>

<p>The following example demonstrates how to use the Natural Language Classifier service:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">NaturalLanguageClassifierV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">naturalLanguageClassifier</span> <span class="o">=</span> <span class="kt">NaturalLanguageClassifier</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">classifierID</span> <span class="o">=</span> <span class="s">"your-trained-classifier-id"</span>
<span class="k">let</span> <span class="nv">text</span> <span class="o">=</span> <span class="s">"your-text-here"</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">naturalLanguageClassifier</span><span class="o">.</span><span class="nf">classify</span><span class="p">(</span><span class="nv">classifierID</span><span class="p">:</span> <span class="n">classifierID</span><span class="p">,</span> <span class="nv">text</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">classification</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">classification</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>The following links provide more information about the Natural Language Classifier service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/natural-language-classifier/">IBM Watson Natural Language Classifier - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/natural-language-classifier/natural-language-classifier-overview.html">IBM Watson Natural Language Classifier - Documentation</a></li>
<li><a href="https://natural-language-classifier-demo.ng.bluemix.net/">IBM Watson Natural Language Classifier - Demo</a></li>
</ul>
<h2 id='natural-language-understanding' class='heading'>Natural Language Understanding</h2>

<p>The IBM Natural Language Understanding service explores various features of text content. Provide text, raw HTML, or a public URL, and IBM Watson Natural Language Understanding will give you results for the features you request. The service cleans HTML content before analysis by default, so the results can ignore most advertisements and other unwanted content.</p>

<p>Natural Language Understanding has the following features:</p>

<ul>
<li>Concepts</li>
<li>Entities</li>
<li>Keywords</li>
<li>Categories</li>
<li>Sentiment</li>
<li>Emotion</li>
<li>Relations</li>
<li>Semantic Roles</li>
</ul>

<p>The following example demonstrates how to use the service:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">NaturalLanguageUnderstandingV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">version</span> <span class="o">=</span> <span class="s">"yyyy-mm-dd"</span> <span class="c1">// use today's date for the most recent version</span>
<span class="k">let</span> <span class="nv">naturalLanguageUnderstanding</span> <span class="o">=</span> <span class="kt">NaturalLanguageUnderstanding</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">features</span> <span class="o">=</span> <span class="kt">Features</span><span class="p">(</span><span class="nv">concepts</span><span class="p">:</span> <span class="kt">ConceptsOptions</span><span class="p">(</span><span class="nv">limit</span><span class="p">:</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">let</span> <span class="nv">parameters</span> <span class="o">=</span> <span class="kt">Parameters</span><span class="p">(</span><span class="nv">features</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span> <span class="nv">text</span><span class="p">:</span> <span class="s">"your-text-here"</span><span class="p">)</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">naturalLanguageUnderstanding</span><span class="o">.</span><span class="nf">analyze</span><span class="p">(</span><span class="nv">parameters</span><span class="p">:</span> <span class="n">parameters</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">results</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>
<h4 id='500-errors' class='heading'>500 errors</h4>

<p>Note that <strong>you are required to include at least one feature in your request.</strong> You will receive a 500 error if you do not include any features in your request.</p>

<p>The following links provide more information about the Natural Language Understanding service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/natural-language-understanding/">IBM Watson Natural Language Understanding - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/natural-language-understanding/index.html">IBM Watson Natural Language Understanding - Documentation</a></li>
<li><a href="https://natural-language-understanding-demo.ng.bluemix.net/">IBM Watson Natural Language Understanding - Demo</a></li>
</ul>
<h2 id='personality-insights' class='heading'>Personality Insights</h2>

<p>The IBM Watson Personality Insights service enables applications to derive insights from social media, enterprise data, or other digital communications. The service uses linguistic analytics to infer personality and social characteristics, including Big Five, Needs, and Values, from text.</p>

<p>The following example demonstrates how to use the Personality Insights service:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">PersonalityInsightsV3</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">version</span> <span class="o">=</span> <span class="s">"yyyy-mm-dd"</span> <span class="c1">// use today's date for the most recent version</span>
<span class="k">let</span> <span class="nv">personalityInsights</span> <span class="o">=</span> <span class="kt">PersonalityInsights</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">personalityInsights</span><span class="o">.</span><span class="nf">profile</span><span class="p">(</span><span class="nv">text</span><span class="p">:</span> <span class="s">"your-input-text"</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span> <span class="n">profile</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">profile</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>The following links provide more information about the Personality Insights service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/personality-insights/">IBM Watson Personality Insights - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/personality-insights/index.html">IBM Watson Personality Insights - Documentation</a></li>
<li><a href="https://personality-insights-demo.ng.bluemix.net/">IBM Watson Personality Insights - Demo</a></li>
</ul>
<h2 id='speech-to-text' class='heading'>Speech to Text</h2>

<p>The IBM Watson Speech to Text service enables you to add speech transcription capabilities to your application. It uses machine intelligence to combine information about grammar and language structure to generate an accurate transcription. Transcriptions are supported for various audio formats and languages.</p>

<p>The <code>SpeechToText</code> class is the SDK&rsquo;s primary interface for performing speech recognition requests. It supports the transcription of audio files, audio data, and streaming microphone data. Advanced users, however, may instead wish to use the <code>SpeechToTextSession</code> class that exposes more control over the WebSockets session.</p>

<p>Please be sure to include both <code>SpeechToTextV1.framework</code> and <code>Starscream.framework</code> in your application. Starscream is a recursive dependency that adds support for WebSockets sessions.</p>

<p>Beginning with iOS 10+, any application that accesses the microphone must include the <code>NSMicrophoneUsageDescription</code> key in the app&rsquo;s <code>Info.plist</code> file. Otherwise, the app will crash. Find more information about this <a href="https://forums.developer.apple.com/thread/61521">here</a>.</p>
<h4 id='recognition-request-settings' class='heading'>Recognition Request Settings</h4>

<p>The <code>RecognitionSettings</code> class is used to define the audio format and behavior of a recognition request. These settings are transmitted to the service when <a href="https://console.bluemix.net/docs/services/speech-to-text/websockets.html#WSstart">initating a request</a>.</p>

<p>The following example demonstrates how to define a recognition request that transcribes WAV audio data with interim results:</p>
<pre class="highlight swift"><code><span class="k">var</span> <span class="nv">settings</span> <span class="o">=</span> <span class="kt">RecognitionSettings</span><span class="p">(</span><span class="nv">contentType</span><span class="p">:</span> <span class="s">"audio/wav"</span><span class="p">)</span>
<span class="n">settings</span><span class="o">.</span><span class="n">interimResults</span> <span class="o">=</span> <span class="kc">true</span>
</code></pre>

<p>See the <a href="http://watson-developer-cloud.github.io/swift-sdk/services/SpeechToTextV1/Structs/RecognitionSettings.html">class documentation</a> or <a href="https://console.bluemix.net/docs/services/speech-to-text/index.html">service documentation</a> for more information about the available settings.</p>
<h4 id='microphone-audio-and-compression' class='heading'>Microphone Audio and Compression</h4>

<p>The Speech to Text framework makes it easy to perform speech recognition with microphone audio. The framework internally manages the microphone, starting and stopping it with various function calls (such as <code>recognizeMicrophone(settings:model:customizationID:learningOptOut:compress:failure:success)</code> and <code>stopRecognizeMicrophone()</code> or <code>startMicrophone(compress:)</code> and <code>stopMicrophone()</code>).</p>

<p>There are two different ways that your app can determine when to stop the microphone:</p>

<ul>
<li><p>User Interaction: Your app could rely on user input to stop the microphone. For example, you could use a button to start/stop transcribing, or you could require users to press-and-hold a button to start/stop transcribing.</p></li>
<li><p>Final Result: Each transcription result has a <code>final</code> property that is <code>true</code> when the audio stream is complete or a timeout has occurred. By watching for the <code>final</code> property, your app can stop the microphone after determining when the user has finished speaking.</p></li>
</ul>

<p>To reduce latency and bandwidth, the microphone audio is compressed to OggOpus format by default. To disable compression, set the <code>compress</code> parameter to <code>false</code>.</p>

<p>It&rsquo;s important to specify the correct audio format for recognition requests that use the microphone:</p>
<pre class="highlight swift"><code><span class="c1">// compressed microphone audio uses the opus format</span>
<span class="k">let</span> <span class="nv">settings</span> <span class="o">=</span> <span class="kt">RecognitionSettings</span><span class="p">(</span><span class="nv">contentType</span><span class="p">:</span> <span class="s">"audio/ogg;codecs=opus"</span><span class="p">)</span>

<span class="c1">// uncompressed microphone audio uses a 16-bit mono PCM format at 16 kHz</span>
<span class="k">let</span> <span class="nv">settings</span> <span class="o">=</span> <span class="kt">RecognitionSettings</span><span class="p">(</span><span class="nv">contentType</span><span class="p">:</span> <span class="s">"audio/l16;rate=16000;channels=1"</span><span class="p">)</span>
</code></pre>
<h4 id='recognition-results-accumulator' class='heading'>Recognition Results Accumulator</h4>

<p>The Speech to Text service may not always return the entire transcription in a single response. Instead, the transcription may be streamed over multiple responses, each with a chunk of the overall results. This is especially common for long audio files, since the entire transcription may contain a significant amount of text.</p>

<p>To help combine multiple responses, the Swift SDK provides a <code>SpeechRecognitionResultsAccumulator</code> object. The accumulator tracks results as they are added and maintains several useful instance variables:
    - <code>results</code>: A list of all accumulated recognition results.
    - <code>speakerLabels</code>: A list of all accumulated speaker labels.
    - <code>bestTranscript</code>: A concatenation of transcripts with the greatest confidence.</p>

<p>To use the accumulator, initialize an instance of the object then add results as you receive them:</p>
<pre class="highlight swift"><code><span class="k">var</span> <span class="nv">accumulator</span> <span class="o">=</span> <span class="kt">SpeechRecognitionResultsAccumulator</span><span class="p">()</span>
<span class="n">accumulator</span><span class="o">.</span><span class="nf">add</span><span class="p">(</span><span class="nv">results</span><span class="p">:</span> <span class="n">results</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">accumulator</span><span class="o">.</span><span class="n">bestTranscript</span><span class="p">)</span>
</code></pre>
<h4 id='transcribe-recorded-audio' class='heading'>Transcribe Recorded Audio</h4>

<p>The following example demonstrates how to use the Speech to Text service to transcribe a WAV audio file.</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">SpeechToTextV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">speechToText</span> <span class="o">=</span> <span class="kt">SpeechToText</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">)</span>

<span class="k">var</span> <span class="nv">accumulator</span> <span class="o">=</span> <span class="kt">SpeechRecognitionResultsAccumulator</span><span class="p">()</span>

<span class="k">let</span> <span class="nv">audio</span> <span class="o">=</span> <span class="kt">Bundle</span><span class="o">.</span><span class="n">main</span><span class="o">.</span><span class="nf">url</span><span class="p">(</span><span class="nv">forResource</span><span class="p">:</span> <span class="s">"filename"</span><span class="p">,</span> <span class="nv">withExtension</span><span class="p">:</span> <span class="s">"wav"</span><span class="p">)</span><span class="o">!</span>
<span class="k">var</span> <span class="nv">settings</span> <span class="o">=</span> <span class="kt">RecognitionSettings</span><span class="p">(</span><span class="nv">contentType</span><span class="p">:</span> <span class="s">"audio/wav"</span><span class="p">)</span>
<span class="n">settings</span><span class="o">.</span><span class="n">interimResults</span> <span class="o">=</span> <span class="kc">true</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">speechToText</span><span class="o">.</span><span class="nf">recognize</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="nv">settings</span><span class="p">:</span> <span class="n">settings</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">results</span> <span class="k">in</span>
    <span class="n">accumulator</span><span class="o">.</span><span class="nf">add</span><span class="p">(</span><span class="nv">results</span><span class="p">:</span> <span class="n">results</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">accumulator</span><span class="o">.</span><span class="n">bestTranscript</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>
<h4 id='transcribe-microphone-audio' class='heading'>Transcribe Microphone Audio</h4>

<p>Audio can be streamed from the microphone to the Speech to Text service for real-time transcriptions. The following example demonstrates how to use the Speech to Text service to transcribe microphone audio:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">SpeechToTextV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">speechToText</span> <span class="o">=</span> <span class="kt">SpeechToText</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">)</span>

<span class="k">var</span> <span class="nv">accumulator</span> <span class="o">=</span> <span class="kt">SpeechRecognitionResultsAccumulator</span><span class="p">()</span>

<span class="kd">func</span> <span class="nf">startStreaming</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">var</span> <span class="nv">settings</span> <span class="o">=</span> <span class="kt">RecognitionSettings</span><span class="p">(</span><span class="nv">contentType</span><span class="p">:</span> <span class="s">"audio/ogg;codecs=opus"</span><span class="p">)</span>
    <span class="n">settings</span><span class="o">.</span><span class="n">interimResults</span> <span class="o">=</span> <span class="kc">true</span>
    <span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
    <span class="n">speechToText</span><span class="o">.</span><span class="nf">recognizeMicrophone</span><span class="p">(</span><span class="nv">settings</span><span class="p">:</span> <span class="n">settings</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span> <span class="n">results</span> <span class="k">in</span>
        <span class="n">accumulator</span><span class="o">.</span><span class="nf">add</span><span class="p">(</span><span class="nv">results</span><span class="p">:</span> <span class="n">results</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">accumulator</span><span class="o">.</span><span class="n">bestTranscript</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">stopStreaming</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">speechToText</span><span class="o">.</span><span class="nf">stopRecognizeMicrophone</span><span class="p">()</span>
<span class="p">}</span>
</code></pre>
<h4 id='session-management-and-advanced-features' class='heading'>Session Management and Advanced Features</h4>

<p>Advanced users may want more customizability than provided by the <code>SpeechToText</code> class. The <code>SpeechToTextSession</code> class exposes more control over the WebSockets connection and also includes several advanced features for accessing the microphone. The <code>SpeechToTextSession</code> class also allows users more control over the AVAudioSession shared instance. Before using <code>SpeechToTextSession</code>, it&rsquo;s helpful to be familiar with the <a href="https://console.bluemix.net/docs/services/speech-to-text/websockets.html">Speech to Text WebSocket interface</a>.</p>

<p>The following steps describe how to execute a recognition request with <code>SpeechToTextSession</code>:</p>

<ol>
<li>Connect: Invoke <code>connect()</code> to connect to the service.</li>
<li>Start Recognition Request: Invoke <code>startRequest(settings:)</code> to start a recognition request.</li>
<li>Send Audio: Invoke <code>recognize(audio:)</code> or <code>startMicrophone(compress:)</code>/<code>stopMicrophone()</code> to send audio to the service.</li>
<li>Stop Recognition Request: Invoke <code>stopRequest()</code> to end the recognition request. If the recognition request is already stopped, then sending a stop message will have no effect.</li>
<li>Disconnect: Invoke <code>disconnect()</code> to wait for any remaining results to be received and then disconnect from the service.</li>
</ol>

<p>All text and data messages sent by <code>SpeechToTextSession</code> are queued, with the exception of <code>connect()</code> which immediately connects to the server. The queue ensures that the messages are sent in-order and also buffers messages while waiting for a connection to be established. This behavior is generally transparent.</p>

<p>A <code>SpeechToTextSession</code> also provides several (optional) callbacks. The callbacks can be used to learn about the state of the session or access microphone data.</p>

<ul>
<li><code>onConnect</code>: Invoked when the session connects to the Speech to Text service.</li>
<li><code>onMicrophoneData</code>: Invoked with microphone audio when a recording audio queue buffer has been filled. If microphone audio is being compressed, then the audio data is in OggOpus format. If uncompressed, then the audio data is in 16-bit PCM format at 16 kHz.</li>
<li><code>onPowerData</code>: Invoked every 0.025s when recording with the average dB power of the microphone.</li>
<li><code>onResults</code>: Invoked when transcription results are received for a recognition request.</li>
<li><code>onError</code>: Invoked when an error or warning occurs.</li>
<li><code>onDisconnect</code>: Invoked when the session disconnects from the Speech to Text service.</li>
</ul>

<p>Note that the <code>AVAudioSession.sharedInstance()</code> must be configured to allow microphone access when using <code>SpeechToTextSession</code>. This allows users to set a particular configuration for the <code>AVAudioSession</code>. An example configuration is shown in the code below.</p>

<p>The following example demonstrates how to use <code>SpeechToTextSession</code> to transcribe microphone audio:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">SpeechToTextV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">speechToTextSession</span> <span class="o">=</span> <span class="kt">SpeechToTextSession</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">)</span>

<span class="k">var</span> <span class="nv">accumulator</span> <span class="o">=</span> <span class="kt">SpeechRecognitionResultsAccumulator</span><span class="p">()</span>

<span class="k">do</span> <span class="p">{</span>
    <span class="k">let</span> <span class="nv">session</span> <span class="o">=</span> <span class="kt">AVAudioSession</span><span class="o">.</span><span class="nf">sharedInstance</span><span class="p">()</span>
    <span class="k">try</span> <span class="n">session</span><span class="o">.</span><span class="nf">setActive</span><span class="p">(</span><span class="kc">true</span><span class="p">)</span>
    <span class="k">try</span> <span class="n">session</span><span class="o">.</span><span class="nf">setCategory</span><span class="p">(</span><span class="kt">AVAudioSessionCategoryPlayAndRecord</span><span class="p">,</span> <span class="nv">with</span><span class="p">:</span> <span class="p">[</span><span class="o">.</span><span class="n">mixWithOthers</span><span class="p">,</span> <span class="o">.</span><span class="n">defaultToSpeaker</span><span class="p">])</span>
<span class="p">}</span> <span class="k">catch</span> <span class="p">{</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">localizedDescription</span><span class="p">)</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">startStreaming</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// define callbacks</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="n">onConnect</span> <span class="o">=</span> <span class="p">{</span> <span class="nf">print</span><span class="p">(</span><span class="s">"connected"</span><span class="p">)</span> <span class="p">}</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="n">onDisconnect</span> <span class="o">=</span> <span class="p">{</span> <span class="nf">print</span><span class="p">(</span><span class="s">"disconnected"</span><span class="p">)</span> <span class="p">}</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="n">onError</span> <span class="o">=</span> <span class="p">{</span> <span class="n">error</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="n">onPowerData</span> <span class="o">=</span> <span class="p">{</span> <span class="n">decibels</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">decibels</span><span class="p">)</span> <span class="p">}</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="n">onMicrophoneData</span> <span class="o">=</span> <span class="p">{</span> <span class="n">data</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="s">"received data"</span><span class="p">)</span> <span class="p">}</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="n">onResults</span> <span class="o">=</span> <span class="p">{</span> <span class="n">results</span> <span class="k">in</span>
        <span class="n">accumulator</span><span class="o">.</span><span class="nf">add</span><span class="p">(</span><span class="nv">results</span><span class="p">:</span> <span class="n">results</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">accumulator</span><span class="o">.</span><span class="n">bestTranscript</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="c1">// define recognition request settings</span>
    <span class="k">var</span> <span class="nv">settings</span> <span class="o">=</span> <span class="kt">RecognitionSettings</span><span class="p">(</span><span class="nv">contentType</span><span class="p">:</span> <span class="s">"audio/ogg;codecs=opus"</span><span class="p">)</span>
    <span class="n">settings</span><span class="o">.</span><span class="n">interimResults</span> <span class="o">=</span> <span class="kc">true</span>

    <span class="c1">// start streaming microphone audio for transcription</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="nf">connect</span><span class="p">()</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="nf">startRequest</span><span class="p">(</span><span class="nv">settings</span><span class="p">:</span> <span class="n">settings</span><span class="p">)</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="nf">startMicrophone</span><span class="p">()</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">stopStreaming</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="nf">stopMicrophone</span><span class="p">()</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="nf">stopRequest</span><span class="p">()</span>
    <span class="n">speechToTextSession</span><span class="o">.</span><span class="nf">disconnect</span><span class="p">()</span>
<span class="p">}</span>
</code></pre>
<h4 id='customization' class='heading'>Customization</h4>

<p>There are a number of ways that Speech to Text can be customized to suit your particular application. For example, you can define custom words or upload audio to train an acoustic model. For more information, refer to the <a href="https://console.bluemix.net/docs/services/speech-to-text/index.html">service documentation</a> or <a href="http://watson-developer-cloud.github.io/swift-sdk/swift-api/services/SpeechToTextV1/Classes/SpeechToText.html">API documentation</a>.</p>
<h4 id='additional-information' class='heading'>Additional Information</h4>

<p>The following links provide more information about the IBM Speech to Text service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/speech-to-text/">IBM Watson Speech to Text - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/speech-to-text/index.html">IBM Watson Speech to Text - Documentation</a></li>
<li><a href="https://speech-to-text-demo.ng.bluemix.net/">IBM Watson Speech to Text - Demo</a></li>
</ul>
<h2 id='text-to-speech' class='heading'>Text to Speech</h2>

<p>The IBM Watson Text to Speech service synthesizes natural-sounding speech from input text in a variety of languages and voices that speak with appropriate cadence and intonation.</p>

<p>The following example demonstrates how to use the Text to Speech service:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">TextToSpeechV1</span>
<span class="kd">import</span> <span class="kt">AVFoundation</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">textToSpeech</span> <span class="o">=</span> <span class="kt">TextToSpeech</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">)</span>

<span class="c1">// The AVAudioPlayer object will stop playing if it falls out-of-scope.</span>
<span class="c1">// Therefore, to prevent it from falling out-of-scope we declare it as</span>
<span class="c1">// a property outside the completion handler where it will be played.</span>
<span class="k">var</span> <span class="nv">audioPlayer</span> <span class="o">=</span> <span class="kt">AVAudioPlayer</span><span class="p">()</span>

<span class="k">let</span> <span class="nv">text</span> <span class="o">=</span> <span class="s">"your-text-here"</span>
<span class="k">let</span> <span class="nv">accept</span> <span class="o">=</span> <span class="s">"audio/wav"</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">textToSpeech</span><span class="o">.</span><span class="nf">synthesize</span><span class="p">(</span><span class="nv">text</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span> <span class="nv">accept</span><span class="p">:</span> <span class="n">accept</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span> <span class="n">data</span> <span class="k">in</span>
    <span class="n">audioPlayer</span> <span class="o">=</span> <span class="k">try!</span> <span class="kt">AVAudioPlayer</span><span class="p">(</span><span class="nv">data</span><span class="p">:</span> <span class="n">data</span><span class="p">)</span>
    <span class="n">audioPlayer</span><span class="o">.</span><span class="nf">prepareToPlay</span><span class="p">()</span>
    <span class="n">audioPlayer</span><span class="o">.</span><span class="nf">play</span><span class="p">()</span>
<span class="p">}</span>
</code></pre>

<p>The Text to Speech service supports a number of <a href="https://console.bluemix.net/docs/services/text-to-speech/http.html#voices">voices</a> for different genders, languages, and dialects. The following example demonstrates how to use the Text to Speech service with a particular voice:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">TextToSpeechV1</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">textToSpeech</span> <span class="o">=</span> <span class="kt">TextToSpeech</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">)</span>

<span class="c1">// The AVAudioPlayer object will stop playing if it falls out-of-scope.</span>
<span class="c1">// Therefore, to prevent it from falling out-of-scope we declare it as</span>
<span class="c1">// a property outside the completion handler where it will be played.</span>
<span class="k">var</span> <span class="nv">audioPlayer</span> <span class="o">=</span> <span class="kt">AVAudioPlayer</span><span class="p">()</span>

<span class="k">let</span> <span class="nv">text</span> <span class="o">=</span> <span class="s">"your-text-here"</span>
<span class="k">let</span> <span class="nv">accept</span> <span class="o">=</span> <span class="s">"audio/wav"</span>
<span class="k">let</span> <span class="nv">voice</span> <span class="o">=</span> <span class="s">"en-US_LisaVoice"</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">textToSpeech</span><span class="o">.</span><span class="nf">synthesize</span><span class="p">(</span><span class="nv">text</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span> <span class="nv">accept</span><span class="p">:</span> <span class="n">accept</span><span class="p">,</span> <span class="nv">voice</span><span class="p">:</span> <span class="n">voice</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span> <span class="n">data</span> <span class="k">in</span>
    <span class="n">audioPlayer</span> <span class="o">=</span> <span class="k">try!</span> <span class="kt">AVAudioPlayer</span><span class="p">(</span><span class="nv">data</span><span class="p">:</span> <span class="n">data</span><span class="p">)</span>
    <span class="n">audioPlayer</span><span class="o">.</span><span class="nf">prepareToPlay</span><span class="p">()</span>
    <span class="n">audioPlayer</span><span class="o">.</span><span class="nf">play</span><span class="p">()</span>
<span class="p">}</span>
</code></pre>

<p>The following links provide more information about the IBM Text To Speech service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/text-to-speech/">IBM Watson Text To Speech - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/text-to-speech/index.html">IBM Watson Text To Speech - Documentation</a></li>
<li><a href="https://text-to-speech-demo.ng.bluemix.net/">IBM Watson Text To Speech - Demo</a></li>
</ul>
<h2 id='tone-analyzer' class='heading'>Tone Analyzer</h2>

<p>The IBM Watson Tone Analyzer service can be used to discover, understand, and revise the language tones in text. The service uses linguistic analysis to detect three types of tones from written text: emotions, social tendencies, and writing style.</p>

<p>Emotions identified include things like anger, fear, joy, sadness, and disgust. Identified social tendencies include things from the Big Five personality traits used by some psychologists. These include openness, conscientiousness, extraversion, agreeableness, and emotional range. Identified writing styles include confident, analytical, and tentative.</p>

<p>The following example demonstrates how to use the Tone Analyzer service:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">ToneAnalyzerV3</span>

<span class="k">let</span> <span class="nv">username</span> <span class="o">=</span> <span class="s">"your-username-here"</span>
<span class="k">let</span> <span class="nv">password</span> <span class="o">=</span> <span class="s">"your-password-here"</span>
<span class="k">let</span> <span class="nv">version</span> <span class="o">=</span> <span class="s">"YYYY-MM-DD"</span> <span class="c1">// use today's date for the most recent version</span>
<span class="k">let</span> <span class="nv">toneAnalyzer</span> <span class="o">=</span> <span class="kt">ToneAnalyzer</span><span class="p">(</span><span class="nv">username</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span> <span class="nv">password</span><span class="p">:</span> <span class="n">password</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">toneInput</span> <span class="o">=</span> <span class="kt">ToneInput</span><span class="p">(</span><span class="nv">text</span><span class="p">:</span> <span class="s">"your-input-text"</span><span class="p">)</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">toneAnalyzer</span><span class="o">.</span><span class="nf">tone</span><span class="p">(</span><span class="nv">toneInput</span><span class="p">:</span> <span class="n">toneInput</span><span class="p">,</span> <span class="nv">contentType</span><span class="p">:</span> <span class="s">"plain/text"</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span> <span class="n">tones</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">tones</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>The following links provide more information about the IBM Watson Tone Analyzer service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/tone-analyzer/">IBM Watson Tone Analyzer - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/tone-analyzer/index.html">IBM Watson Tone Analyzer - Documentation</a></li>
<li><a href="https://tone-analyzer-demo.ng.bluemix.net/">IBM Watson Tone Analyzer - Demo</a></li>
</ul>
<h2 id='visual-recognition' class='heading'>Visual Recognition</h2>

<p>The IBM Watson Visual Recognition service uses deep learning algorithms to analyze images (.jpg or .png) for scenes, objects, faces, text, and other content, and return keywords that provide information about that content. The service comes with a set of built-in classes so that you can analyze images with high accuracy right out of the box. You can also train custom classifiers to create specialized classes.</p>

<p>The following example demonstrates how to use the Visual Recognition service:</p>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">VisualRecognitionV3</span>

<span class="k">let</span> <span class="nv">apiKey</span> <span class="o">=</span> <span class="s">"your-apikey-here"</span>
<span class="k">let</span> <span class="nv">version</span> <span class="o">=</span> <span class="s">"YYYY-MM-DD"</span> <span class="c1">// use today's date for the most recent version</span>
<span class="k">let</span> <span class="nv">visualRecognition</span> <span class="o">=</span> <span class="kt">VisualRecognition</span><span class="p">(</span><span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">,</span> <span class="nv">apiKey</span><span class="p">:</span> <span class="n">apiKey</span><span class="p">)</span>

<span class="k">let</span> <span class="nv">url</span> <span class="o">=</span> <span class="s">"your-image-url"</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">visualRecognition</span><span class="o">.</span><span class="nf">classify</span><span class="p">(</span><span class="nv">image</span><span class="p">:</span> <span class="n">url</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span> <span class="n">classifiedImages</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">classifiedImages</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>Note: a different initializer is used for authentication with instances created before May 23, 2018:</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">visualRecognition</span> <span class="o">=</span> <span class="kt">VisualRecognition</span><span class="p">(</span><span class="nv">apiKey</span><span class="p">:</span> <span class="n">apiKey</span><span class="p">,</span> <span class="nv">version</span><span class="p">:</span> <span class="n">version</span><span class="p">)</span>
</code></pre>
<h3 id='using-core-ml' class='heading'>Using Core ML</h3>

<p>The Watson Swift SDK supports offline image classification using Apple Core ML. Classifiers must be trained or updated with the <code>coreMLEnabled</code> flag set to true. Once the classifier&rsquo;s <code>coreMLStatus</code> is <code>ready</code> then a Core ML model is available to download and use for offline classification. </p>

<p>Once the Core ML model is in the device&rsquo;s file system, images can be classified offline, directly on the device.</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">classifierID</span> <span class="o">=</span> <span class="s">"your-classifier-id"</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="k">let</span> <span class="nv">image</span> <span class="o">=</span> <span class="kt">UIImage</span><span class="p">(</span><span class="nv">named</span><span class="p">:</span> <span class="s">"your-image-filename"</span><span class="p">)</span>
<span class="n">visualRecognition</span><span class="o">.</span><span class="nf">classifyWithLocalModel</span><span class="p">(</span><span class="nv">image</span><span class="p">:</span> <span class="n">image</span><span class="p">,</span> <span class="nv">classifierIDs</span><span class="p">:</span> <span class="p">[</span><span class="n">classifierID</span><span class="p">],</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">classifiedImages</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">classifiedImages</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>The local Core ML model can be updated as needed.</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">classifierID</span> <span class="o">=</span> <span class="s">"your-classifier-id"</span>
<span class="k">let</span> <span class="nv">failure</span> <span class="o">=</span> <span class="p">{</span> <span class="p">(</span><span class="nv">error</span><span class="p">:</span> <span class="kt">Error</span><span class="p">)</span> <span class="k">in</span> <span class="nf">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="p">}</span>
<span class="n">visualRecognition</span><span class="o">.</span><span class="nf">updateLocalModel</span><span class="p">(</span><span class="nv">classifierID</span><span class="p">:</span> <span class="n">classifierID</span><span class="p">,</span> <span class="nv">failure</span><span class="p">:</span> <span class="n">failure</span><span class="p">)</span> <span class="p">{</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"model updated"</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>

<p>The following example demonstrates how to list the Core ML models that are stored in the filesystem and available for offline use:</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">localModels</span> <span class="o">=</span> <span class="k">try!</span> <span class="n">visualRecognition</span><span class="o">.</span><span class="nf">listLocalModels</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">localModels</span><span class="p">)</span>
</code></pre>

<p>If you would prefer to bypass <code>classifyWithLocalModel</code> and construct your own Core ML classification request, then you can retrieve a Core ML model from the local filesystem with the following example.</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">classifierID</span> <span class="o">=</span> <span class="s">"your-classifier-id"</span>
<span class="k">let</span> <span class="nv">localModel</span> <span class="o">=</span> <span class="k">try!</span> <span class="n">visualRecognition</span><span class="o">.</span><span class="nf">getLocalModel</span><span class="p">(</span><span class="nv">classifierID</span><span class="p">:</span> <span class="n">classifierID</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">localModel</span><span class="p">)</span>
</code></pre>

<p>The following example demonstrates how to delete a local Core ML model from the filesystem. This saves space when the model is no longer needed.</p>
<pre class="highlight swift"><code><span class="k">let</span> <span class="nv">classifierID</span> <span class="o">=</span> <span class="s">"your-classifier-id"</span>
<span class="n">visualRecognition</span><span class="o">.</span><span class="nf">deleteLocalModel</span><span class="p">(</span><span class="nv">classifierID</span><span class="p">:</span> <span class="n">classifierID</span><span class="p">)</span>
</code></pre>
<h4 id='bundling-a-model-directly-with-your-application' class='heading'>Bundling a model directly with your application</h4>

<p>You may also choose to include a Core ML model with your application, enabling images to be classified offline without having to download a model first. To include a model, add it to your application bundle following the naming convention [classifier_id].mlmodel. This will enable the SDK to locate the model when using any function that accepts a classifierID argument.</p>

<p>The following links provide more information about the IBM Watson Visual Recognition service:</p>

<ul>
<li><a href="https://www.ibm.com/watson/services/visual-recognition/">IBM Watson Visual Recognition - Service Page</a></li>
<li><a href="https://console.bluemix.net/docs/services/visual-recognition/index.html">IBM Watson Visual Recognition - Documentation</a></li>
<li><a href="https://visual-recognition-demo.ng.bluemix.net/">IBM Watson Visual Recognition - Demo</a></li>
</ul>

          </section>
        </section>
        <section id="footer">
          <p>&copy; 2018 <a class="link" href="" target="_blank" rel="external"></a>. All rights reserved. (Last updated: 2018-06-29)</p>
          <p>Generated by <a class="link" href="https://github.com/realm/jazzy" target="_blank" rel="external">jazzy ♪♫ v0.9.3</a>, a <a class="link" href="https://realm.io" target="_blank" rel="external">Realm</a> project.</p>
        </section>
      </article>
    </div>
  </body>
</div>
</html>
